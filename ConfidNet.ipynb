{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPV8MbYSHgbgtyDuUMqu/cL",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jhotchk2/ConfidNet/blob/main/ConfidNet.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1B8JiEmA-u-_",
        "outputId": "70faccb8-2d18-46f3-9ac0-97be5fb5323a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'ConfidNet'...\n",
            "remote: Enumerating objects: 138, done.\u001b[K\n",
            "remote: Counting objects: 100% (76/76), done.\u001b[K\n",
            "remote: Compressing objects: 100% (36/36), done.\u001b[K\n",
            "remote: Total 138 (delta 47), reused 40 (delta 40), pack-reused 62 (from 1)\u001b[K\n",
            "Receiving objects: 100% (138/138), 196.34 KiB | 8.54 MiB/s, done.\n",
            "Resolving deltas: 100% (66/66), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/valeoai/ConfidNet.git"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd ConfidNet"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sSSYJYE3_ifN",
        "outputId": "0fdc8f35-69b3-462a-c13b-4de802f50c1d"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/ConfidNet\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -e ."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JAcG7nib_oCJ",
        "outputId": "929f565c-9342-4381-a0bc-18672b7e3ce2"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Obtaining file:///content/ConfidNet\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.11/dist-packages (from ConfidNet==0.1.0) (6.0.2)\n",
            "Collecting coloredlogs (from ConfidNet==0.1.0)\n",
            "  Downloading coloredlogs-15.0.1-py2.py3-none-any.whl.metadata (12 kB)\n",
            "Requirement already satisfied: torchsummary in /usr/local/lib/python3.11/dist-packages (from ConfidNet==0.1.0) (1.5.1)\n",
            "Collecting verboselogs (from ConfidNet==0.1.0)\n",
            "  Downloading verboselogs-1.7-py2.py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from ConfidNet==0.1.0) (75.1.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from ConfidNet==0.1.0) (4.67.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.11/dist-packages (from ConfidNet==0.1.0) (8.1.8)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (from ConfidNet==0.1.0) (1.6.1)\n",
            "Collecting humanfriendly>=9.1 (from coloredlogs->ConfidNet==0.1.0)\n",
            "  Downloading humanfriendly-10.0-py2.py3-none-any.whl.metadata (9.2 kB)\n",
            "Requirement already satisfied: numpy>=1.19.5 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->ConfidNet==0.1.0) (1.26.4)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->ConfidNet==0.1.0) (1.13.1)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->ConfidNet==0.1.0) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->ConfidNet==0.1.0) (3.5.0)\n",
            "Downloading coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m858.1 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading verboselogs-1.7-py2.py3-none-any.whl (11 kB)\n",
            "Downloading humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: verboselogs, humanfriendly, coloredlogs, ConfidNet\n",
            "  Running setup.py develop for ConfidNet\n",
            "Successfully installed ConfidNet-0.1.0 coloredlogs-15.0.1 humanfriendly-10.0 verboselogs-1.7\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd confidnet/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-8GhzPfT__CX",
        "outputId": "8c05b792-0bd6-4867-ef8e-f2078d910d39"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/ConfidNet/confidnet\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python3 train.py -c confs/exp_cifar10.yaml"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WbesyJLIAHem",
        "outputId": "16d5d757-aca7-450e-a220-2975bc0882b8"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025-02-21 01:55:16.908651: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1740102916.936146    1074 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1740102916.944114    1074 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2025-02-21 01:55:16.971392: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "\u001b[32m2025-02-21 01:55:20,866\u001b[0m \u001b[35mf97ef3698dcf\u001b[0m \u001b[34m__main__[1074]\u001b[0m \u001b[1;90mINFO\u001b[0m Starting from scratch\n",
            "\u001b[32m2025-02-21 01:55:20,866\u001b[0m \u001b[35mf97ef3698dcf\u001b[0m \u001b[34m__main__[1074]\u001b[0m \u001b[1;90mINFO\u001b[0m Loading dataset cifar10\n",
            "\u001b[32m2025-02-21 01:55:20,866\u001b[0m \u001b[35mf97ef3698dcf\u001b[0m \u001b[34mconfidnet.loaders.loader[1074]\u001b[0m \u001b[1;90mINFO\u001b[0m --- Augmentations ---\n",
            "\u001b[32m2025-02-21 01:55:20,866\u001b[0m \u001b[35mf97ef3698dcf\u001b[0m \u001b[34mconfidnet.augmentations[1074]\u001b[0m \u001b[1;90mINFO\u001b[0m Using hflip aug with params True\n",
            "\u001b[32m2025-02-21 01:55:20,867\u001b[0m \u001b[35mf97ef3698dcf\u001b[0m \u001b[34mconfidnet.augmentations[1074]\u001b[0m \u001b[1;90mINFO\u001b[0m Using rotate aug with params 15\n",
            "\u001b[32m2025-02-21 01:55:20,867\u001b[0m \u001b[35mf97ef3698dcf\u001b[0m \u001b[34mconfidnet.augmentations[1074]\u001b[0m \u001b[1;90mINFO\u001b[0m Using No Augmentations\n",
            "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to data/cifar10-data/cifar-10-python.tar.gz\n",
            "100% 170M/170M [00:01<00:00, 106MB/s]\n",
            "Extracting data/cifar10-data/cifar-10-python.tar.gz to data/cifar10-data\n",
            "Files already downloaded and verified\n",
            "/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:617: UserWarning: This DataLoader will create 3 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "\u001b[32m2025-02-21 01:55:26,777\u001b[0m \u001b[35mf97ef3698dcf\u001b[0m \u001b[34m__main__[1074]\u001b[0m \u001b[1;90mWARNING\u001b[0m \u001b[33mLearning type: default\u001b[0m\n",
            "\u001b[32m2025-02-21 01:55:27,071\u001b[0m \u001b[35mf97ef3698dcf\u001b[0m \u001b[34mconfidnet.learners.learner[1074]\u001b[0m \u001b[1;90mINFO\u001b[0m Using optimizer sgd\n",
            "\u001b[32m2025-02-21 01:55:27,072\u001b[0m \u001b[35mf97ef3698dcf\u001b[0m \u001b[34mconfidnet.learners.learner[1074]\u001b[0m \u001b[1;90mINFO\u001b[0m Using loss cross_entropy\n",
            "\u001b[32m2025-02-21 01:55:27,072\u001b[0m \u001b[35mf97ef3698dcf\u001b[0m \u001b[34m__main__[1074]\u001b[0m \u001b[1;90mINFO\u001b[0m Loading pretrained model from vgg16\n",
            "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=VGG16_Weights.IMAGENET1K_V1`. You can also use `weights=VGG16_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            "Downloading: \"https://download.pytorch.org/models/vgg16-397923af.pth\" to /root/.cache/torch/hub/checkpoints/vgg16-397923af.pth\n",
            "100% 528M/528M [00:04<00:00, 137MB/s]\n",
            "\u001b[32m2025-02-21 01:55:33,881\u001b[0m \u001b[35mf97ef3698dcf\u001b[0m \u001b[34m__main__[1074]\u001b[0m \u001b[1;90mINFO\u001b[0m Using model vgg16\n",
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "   ReflectionPad2d-1            [-1, 3, 34, 34]               0\n",
            "            Conv2d-2           [-1, 64, 32, 32]           1,792\n",
            "        Conv2dSame-3           [-1, 64, 32, 32]               0\n",
            "       BatchNorm2d-4           [-1, 64, 32, 32]             128\n",
            "           Dropout-5           [-1, 64, 32, 32]               0\n",
            "   ReflectionPad2d-6           [-1, 64, 34, 34]               0\n",
            "            Conv2d-7           [-1, 64, 32, 32]          36,928\n",
            "        Conv2dSame-8           [-1, 64, 32, 32]               0\n",
            "       BatchNorm2d-9           [-1, 64, 32, 32]             128\n",
            "        MaxPool2d-10           [-1, 64, 16, 16]               0\n",
            "  ReflectionPad2d-11           [-1, 64, 18, 18]               0\n",
            "           Conv2d-12          [-1, 128, 16, 16]          73,856\n",
            "       Conv2dSame-13          [-1, 128, 16, 16]               0\n",
            "      BatchNorm2d-14          [-1, 128, 16, 16]             256\n",
            "          Dropout-15          [-1, 128, 16, 16]               0\n",
            "  ReflectionPad2d-16          [-1, 128, 18, 18]               0\n",
            "           Conv2d-17          [-1, 128, 16, 16]         147,584\n",
            "       Conv2dSame-18          [-1, 128, 16, 16]               0\n",
            "      BatchNorm2d-19          [-1, 128, 16, 16]             256\n",
            "        MaxPool2d-20            [-1, 128, 8, 8]               0\n",
            "  ReflectionPad2d-21          [-1, 128, 10, 10]               0\n",
            "           Conv2d-22            [-1, 256, 8, 8]         295,168\n",
            "       Conv2dSame-23            [-1, 256, 8, 8]               0\n",
            "      BatchNorm2d-24            [-1, 256, 8, 8]             512\n",
            "          Dropout-25            [-1, 256, 8, 8]               0\n",
            "  ReflectionPad2d-26          [-1, 256, 10, 10]               0\n",
            "           Conv2d-27            [-1, 256, 8, 8]         590,080\n",
            "       Conv2dSame-28            [-1, 256, 8, 8]               0\n",
            "      BatchNorm2d-29            [-1, 256, 8, 8]             512\n",
            "          Dropout-30            [-1, 256, 8, 8]               0\n",
            "  ReflectionPad2d-31          [-1, 256, 10, 10]               0\n",
            "           Conv2d-32            [-1, 256, 8, 8]         590,080\n",
            "       Conv2dSame-33            [-1, 256, 8, 8]               0\n",
            "      BatchNorm2d-34            [-1, 256, 8, 8]             512\n",
            "        MaxPool2d-35            [-1, 256, 4, 4]               0\n",
            "  ReflectionPad2d-36            [-1, 256, 6, 6]               0\n",
            "           Conv2d-37            [-1, 512, 4, 4]       1,180,160\n",
            "       Conv2dSame-38            [-1, 512, 4, 4]               0\n",
            "      BatchNorm2d-39            [-1, 512, 4, 4]           1,024\n",
            "          Dropout-40            [-1, 512, 4, 4]               0\n",
            "  ReflectionPad2d-41            [-1, 512, 6, 6]               0\n",
            "           Conv2d-42            [-1, 512, 4, 4]       2,359,808\n",
            "       Conv2dSame-43            [-1, 512, 4, 4]               0\n",
            "      BatchNorm2d-44            [-1, 512, 4, 4]           1,024\n",
            "          Dropout-45            [-1, 512, 4, 4]               0\n",
            "  ReflectionPad2d-46            [-1, 512, 6, 6]               0\n",
            "           Conv2d-47            [-1, 512, 4, 4]       2,359,808\n",
            "       Conv2dSame-48            [-1, 512, 4, 4]               0\n",
            "      BatchNorm2d-49            [-1, 512, 4, 4]           1,024\n",
            "        MaxPool2d-50            [-1, 512, 2, 2]               0\n",
            "  ReflectionPad2d-51            [-1, 512, 4, 4]               0\n",
            "           Conv2d-52            [-1, 512, 2, 2]       2,359,808\n",
            "       Conv2dSame-53            [-1, 512, 2, 2]               0\n",
            "      BatchNorm2d-54            [-1, 512, 2, 2]           1,024\n",
            "          Dropout-55            [-1, 512, 2, 2]               0\n",
            "  ReflectionPad2d-56            [-1, 512, 4, 4]               0\n",
            "           Conv2d-57            [-1, 512, 2, 2]       2,359,808\n",
            "       Conv2dSame-58            [-1, 512, 2, 2]               0\n",
            "      BatchNorm2d-59            [-1, 512, 2, 2]           1,024\n",
            "          Dropout-60            [-1, 512, 2, 2]               0\n",
            "  ReflectionPad2d-61            [-1, 512, 4, 4]               0\n",
            "           Conv2d-62            [-1, 512, 2, 2]       2,359,808\n",
            "       Conv2dSame-63            [-1, 512, 2, 2]               0\n",
            "      BatchNorm2d-64            [-1, 512, 2, 2]           1,024\n",
            "        MaxPool2d-65            [-1, 512, 1, 1]               0\n",
            "          Dropout-66            [-1, 512, 1, 1]               0\n",
            "           Linear-67                  [-1, 512]         262,656\n",
            "          Dropout-68                  [-1, 512]               0\n",
            "           Linear-69                   [-1, 10]           5,130\n",
            "================================================================\n",
            "Total params: 14,990,922\n",
            "Trainable params: 14,990,922\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.01\n",
            "Forward/backward pass size (MB): 9.83\n",
            "Params size (MB): 57.19\n",
            "Estimated Total Size (MB): 67.02\n",
            "----------------------------------------------------------------\n",
            "2025-02-21 01:55:34.177750: E external/local_xla/xla/stream_executor/cuda/cuda_driver.cc:152] failed call to cuInit: INTERNAL: CUDA error: Failed call to cuInit: UNKNOWN ERROR (303)\n",
            "\u001b[32m2025-02-21 01:55:34,208\u001b[0m \u001b[35mf97ef3698dcf\u001b[0m \u001b[34m__main__[1074]\u001b[0m \u001b[1;90mINFO\u001b[0m Sending batches as (128, 3, 32, 32)\n",
            "\u001b[32m2025-02-21 01:55:34,208\u001b[0m \u001b[35mf97ef3698dcf\u001b[0m \u001b[34m__main__[1074]\u001b[0m \u001b[1;90mINFO\u001b[0m Saving logs in: /content/output-cifar10\n",
            "\u001b[32m2025-02-21 01:55:34,209\u001b[0m \u001b[35mf97ef3698dcf\u001b[0m \u001b[34mconfidnet.utils.schedulers[1074]\u001b[0m \u001b[1;90mINFO\u001b[0m Using No LR Scheduling\n",
            "Epoch 1/250:   1% 4/352 [00:45<1:05:18, 11.26s/it, loss_nll=1.9828e-02, acc=9.96%]\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/ConfidNet/confidnet/train.py\", line 135, in <module>\n",
            "    main()\n",
            "  File \"/content/ConfidNet/confidnet/train.py\", line 131, in main\n",
            "    learner.train(epoch)\n",
            "  File \"/content/ConfidNet/confidnet/learners/default_learner.py\", line 34, in train\n",
            "    current_loss.backward()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 581, in backward\n",
            "    torch.autograd.backward(\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
            "    _engine_run_backward(\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 825, in _engine_run_backward\n",
            "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "KeyboardInterrupt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python3 test.py -c confs/exp_cifar10.yaml -e 250 -m confidnet"
      ],
      "metadata": {
        "id": "su4HEAJT-I96"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}